## Try to Ensure Explainability



## Always Document Biases and Shortcomings



## Evaluate whether the Model can be Used for Harm

As Deep Learning becomes more and more advanced and the potential impact that the trained models can have on society as a whole grows larger and larger, it is important to truly evaluate whether or not these models should be made publically available. In June 2020, The team at OpenAI created a language model that can create human-like text (GPT-3). They decided, however, that acccess would be tightly controlled and the general public would not be given unrestricted access to it. They figured that the potential harm, with fake news generationg etc. was simply to great. Users need to join a waitlist[1] and describe, in detail, what their use case will be. This is a good example of a team realising the potential harm their model could cause and strongly considering the ethics behind making it public. 

#### References

1 - [OpenAI GPT-3 Waitlist](https://share.hsforms.com/1Lfc7WtPLRk2ppXhPjcYY-A4sk30)
