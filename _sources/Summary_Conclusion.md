## Summary

As this was the last assignment of the semester, and it had quite a nice scope for our own ideas, we decided to have multiple different facets. We knew that the main thing that had to be created was a recommender system for the last.fm dataset. We set out to tackle that with the google colab book that Tomas had shared with us. It was tricky to adapt many parts of it to our use case so it wasn't quite as straightforward as we had anticipated, leaving us having to make some assumptions and use our gut instinct. Creating ratings out of the "weighting", for example. This was enjoyable though, and felt rewarding when we got some outstanding results from our recommender system. 

We then decided it would be great to integrate our own Spotify data to test out the system. We incorporated the Spotify Web API so we could achieve this task. We had some big challenges getting the authentication token to work but once we overcame that we were then able to create a nice list of recommendations based on a user's Spotify listening habits. It actually fared quite well against Spotify's own recommendations, though we are quite hamstrung by the last.fm data only being as recent as 2011. 

Our next port of call was to try out some clustering, as a nod to Assignment one. We decided to try out T-distributed Stochastic Neighbour Modelling (TSNE) due to the high dimensionality of the data. While we had used PCA in the past for a similar task, we wanted to try something novel. We got some interesting visualisations of the clustering but unfortunately were unable to make a solid conclusion as to what was creating a particular strange cluster. It was nice to get some TSNE use under our belts though.

Finally we decided that we should try to use some graph analysis on the data. The dataset contained links between friends which let us visualise these user friendships on a graph. This led to some interesting insights as to who the most connected users were. We discovered there were many mini communities on the edges of the graph, and a much larger central community right in the middle.

## Learning Outcomes

For all three of us, this was our first encounter with recommender systems and we definitely learned a great deal throughout the assignment. The Google tutorial, which we used as a reference point throughout the project, was hugely informative. It was very interesting to get an insight into the different techniques which form the basis of recommender systems, considering most of us implicitly interact with them every day. A central component of the project was figuring out how to represent the hugely skewed listening counts for each user and artist. Through exploring different normalisation techniques, we learned a great deal. We found that striking a balance between mitigating against the effect of said outliers while also preserving their raw occurrence throughout the data is a key part of managing them effectively and this is definitely something which we will all be more careful of in later projects.

Although we had all used the Tensorflow framework before, it definitely does take some getting used to. We learned a lot throughout the project about the different data structures and functionalities which TF has and more importantly, how to take advantage of these. As with the previous assignments, there is no doubt that many of us will encounter recommender systems in industry and the concepts and practical skills which we learned through battling with this assignment will definitely stand to us.
