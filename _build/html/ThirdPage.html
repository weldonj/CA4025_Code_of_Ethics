
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Try to Ensure Explainability &#8212; CA4025 - Data Science Code of Ethics - John Weldon</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Ensure Stored Data is Safe and Secure" href="FourthPage.html" />
    <link rel="prev" title="Always be Honest with Results and Findings" href="SecondPage.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/ethics.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">CA4025 - Data Science Code of Ethics - John Weldon</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Overview.html">
   OVERVIEW AND UNDERLYING MANTRA
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data Collection
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="FirstPage.html">
   Ensure Informed Consent is Obtained
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FirstPage.html#only-collect-data-that-is-relevant-for-the-proposed-project">
   Only Collect Data that is Relevant for the Proposed Project
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FirstPage.html#try-to-ensure-that-the-data-is-truly-representative">
   Try to Ensure that the Data is Truly Representative
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data Analysis
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="SecondPage.html">
   Always be Honest with Results and Findings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="SecondPage.html#limit-exposure-of-personally-identifiable-information">
   Limit Exposure of Personally Identifiable Information
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="SecondPage.html#ensure-that-the-work-is-reproducible">
   Ensure that the Work is Reproducible
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data Modelling
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Try to Ensure Explainability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#always-document-biases-and-shortcomings">
   Always Document Biases and Shortcomings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="#evaluate-whether-the-model-can-be-used-for-harm">
   Evaluate whether the Model can be Used for Harm
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Data Storage
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="FourthPage.html">
   Ensure Stored Data is Safe and Secure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FourthPage.html#plan-for-eventual-deletion">
   Plan for Eventual Deletion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FourthPage.html#create-simple-process-for-subjects-to-request-deletion">
   Create Simple Process for Subjects to Request Deletion
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Team Structure and Environmental Concerns
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="FifthPage.html">
   Consider the Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="FifthPage.html#create-diverse-teams">
   Create Diverse Teams
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/ThirdPage.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Try to Ensure Explainability
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#always-document-biases-and-shortcomings">
   Always Document Biases and Shortcomings
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-whether-the-model-can-be-used-for-harm">
   Evaluate whether the Model can be Used for Harm
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#references">
     References
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="try-to-ensure-explainability">
<h1>Try to Ensure Explainability<a class="headerlink" href="#try-to-ensure-explainability" title="Permalink to this headline">¶</a></h1>
<p>By their nature, deep neural networks produce outcomes that are very difficult to interpret. While it can be easy to see how accurate the models are, it is rarely possible to understand why they make the decisions that they do. For the most part this has simply been accepted as a downside worth tolerating, but there is a growing push for explainable AI with lots of new research in this area. Wherever possible, a team should try to ensure as much explainability as possible, making it easier to see bias within the model. For example, there have been reports of robot judges in the US being inherently racist due to the data they have been trained on, and being more likely to hand down harsh sentences to African Americans and also label them as more likely to re-offend[1]. This is one example where explainability would be important. If it’s clear that these decisions are a result of biased training data, it’s much easier to stop this unfair process from happening.</p>
</div>
<div class="section" id="always-document-biases-and-shortcomings">
<h1>Always Document Biases and Shortcomings<a class="headerlink" href="#always-document-biases-and-shortcomings" title="Permalink to this headline">¶</a></h1>
<p>There will be times when bias is just a part of the process and is not avoidable. In these cases, a team should document them and perhaps explain why they are there and how they are being accounted for. It doesn’t mean that the project is particularly flawed or unethical, it’s just the nature of certain data sources. The problem arises if there is an attempt made to hide the biases of shortcomings and just pretend they don’t exist.</p>
</div>
<div class="section" id="evaluate-whether-the-model-can-be-used-for-harm">
<h1>Evaluate whether the Model can be Used for Harm<a class="headerlink" href="#evaluate-whether-the-model-can-be-used-for-harm" title="Permalink to this headline">¶</a></h1>
<p>As Deep Learning becomes more and more advanced and the potential impact that the trained models can have on society as a whole grows larger and larger, it is important to truly evaluate whether or not these models should be made publically available. In June 2020, The team at OpenAI created a language model that can create human-like text (GPT-3). They decided, however, that access would be tightly controlled and the general public would not be given unrestricted access to it. They figured that the potential harm, with fake news generation etc. was simply too great. Users need to join a waitlist[2] and describe, in detail, what their use case will be. This is a good example of a team realising the potential harm their model could cause and strongly considering the ethics behind making it public.</p>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>1 - <a class="reference external" href="https://www.theguardian.com/inequality/2017/aug/08/rise-of-the-racist-robots-how-ai-is-learning-all-our-worst-impulses">Rise of the racist robots – how AI is learning all our worst impulses</a></p>
<p>2 - <a class="reference external" href="https://share.hsforms.com/1Lfc7WtPLRk2ppXhPjcYY-A4sk30">OpenAI GPT-3 Waitlist</a></p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="SecondPage.html" title="previous page">Always be Honest with Results and Findings</a>
    <a class='right-next' id="next-link" href="FourthPage.html" title="next page">Ensure Stored Data is Safe and Secure</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>